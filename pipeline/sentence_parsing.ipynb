{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sentence Parsing**\n",
    "\n",
    "The goal of this script is to experiment with sentence parsing, to tightly associate nouns with their descriptive terminology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries, initialize spaCy\n",
    "\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import spacy as sp\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from spacy import displacy\n",
    "import joblib\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "\n",
    "#The 'xx' dataset is the biggest multilanguage one.  It catches the most names\n",
    "#The 'en' dataset does the best job of parsing organizations and labels verbs and other parts of speech\n",
    "# Install model with `python -m spacy download en`\n",
    "nlp = sp.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the genderize data\n",
    "genderize = pd.read_csv(\"../source_data/genderizer_collected.csv\").set_index('name')\n",
    "genderize.head()\n",
    "known_names = set(genderize.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The project was supported by a start-up funding provided to the author by the  Department of Neurology of the University of Utah . This project was inspired by studying the work of Dr. Ed Dudek and the results of the initial experiments were discussed with him. I am also grateful to Dr. Erika Scholl for her assistance in measuring rat serum osmolarity and to Dr. Noel Carlson for his insightful comments on the manuscript.\n",
      "\n",
      "This project was inspired by studying the work of Dr. Ed Dudek and the results of the initial experiments were discussed with him.\n",
      "I am also grateful to Dr. Erika Scholl for her assistance in measuring rat serum osmolarity and to Dr. Noel Carlson for his insightful comments on the manuscript.\n"
     ]
    }
   ],
   "source": [
    "# Sample read\n",
    "sample = '<ack><title>Acknowledgements</title><p>The authors wish to acknowledge Diya Ma, Matthew-Lun Wong, Ka-Long Ko, Ka-Hei Ko and Jin-Peng Lee for their important contributions to the software development.</p><sec id=\"\"FPar1\"\"><title>Funding</title><p id=\"\"Par28\"\">The work described in this paper was supported by a grant from the Research Grants Council of the Hong Kong Special Administrative Region, China (Project No.: CUHK 14113214), grants from the Innovation and Technology Commission (Project No: ITS/149/14FP, GHP/028/14SZ, ITS/293/14FP), grants from CUHK Technology and Business Development Fund (Project No.: TBF16MED002, TBF16MED004), a grant from The Science, Technology and Innovation Commission of Shenzhen Municipality (Project No.: CXZZ20140606164105361), and a grant from The Scientific Research Project of Guangdong Province (Project No.: 2014B090901055).</p></sec></ack>'\n",
    "sample = '<ack id=\"\"ack0010\"\"><title>Acknowledgements</title><p>The authors thank Dr. R Kaneko for the gift of the iSip2 vector; and Mss. T Honma, K Harada, A Morita, and Y Shimoda for providing technical and secretarial assistance. We thank the staff at the Department of Genetic and Behavioral Neuroscience and Bioresource Center, Gunma University Graduate School of Medicine for their critical comments and technical assistance. This study was supported by <funding-source id=\"\"gs1\"\">Grants-in-Aid for Scientific Research</funding-source> (23115503, 26290002, 15H01415 and 15H05872 to Y.Y.), a Grant-in-Aid for Scientific Research on Innovative Areas (Comprehensive Brain Science Network) (to Y.Y.) from the <funding-source id=\"\"gs2\"\">Ministry of Education, Culture, Sports, Science and Technology (MEXT)</funding-source> of Japan, a grant from the Co-operative Study Program of the <funding-source id=\"\"gs3\"\">National Institute for Physiological Sciences</funding-source>, Japan (to Y.Y.), and a grant from the <funding-source id=\"\"gs4\"\">Takeda Science Foundation</funding-source> (to Y.Y.).</p></ack>'\n",
    "sample = u'<ack id=\"\"ack0005\"\"><title>Acknowledgments</title><p>The project was supported by a start-up funding provided to the author by the <funding-source id=\"\"gs0005\"\">Department of Neurology of the University of Utah</funding-source>.</p><p>This project was inspired by studying the work of Dr. Ed Dudek and the results of the initial experiments were discussed with him.</p><p>I am also grateful to Dr. Erika Scholl for her assistance in measuring rat serum osmolarity and to Dr. Noel Carlson for his insightful comments on the manuscript.</p></ack>'\n",
    "\n",
    "soup = BeautifulSoup(sample,'lxml')\n",
    "for ele in soup.find_all('title'):\n",
    "    ele.decompose()\n",
    "samp_txt = soup.find_all('ack')[0].get_text(separator=' ')\n",
    "\n",
    "print(samp_txt)\n",
    "print()\n",
    "doc = nlp(samp_txt)\n",
    "\n",
    "for sent in doc.sents:\n",
    "    if 'fund' in sent.text or 'grant' in sent.text: continue #if it's a funding sentence, we don't care\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a good start, but we need to split up the individual parts of sentences which refer to multiple people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This project was inspired by studying the work of Dr. Ed Dudek and the results of the initial experiments were discussed with him.\n",
      "I am also grateful to Dr. Erika Scholl for her assistance in measuring rat serum osmolarity and to Dr. Noel Carlson for his insightful comments on the manuscript.\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    if 'fund' in sent.text or 'grant' in sent.text or 'supported' in sent.text or 'financ' in sent.text: continue #if it's a funding sentence, we don't care\n",
    "    #count nouns\n",
    "    sentdoc = nlp(sent.text) #if this needs speed optimization, we can search by start-stop characters instead\n",
    "    sentppl = [n for n in sentdoc.ents if n.label_ == 'PERSON']\n",
    "    people_count = len(sentppl)\n",
    "    if people_count == 0: continue #no named people, disregard\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actually run the thing on the real stuff\n",
    "F_CSV = glob.glob(\"../source_data/extracted/*.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_df(row, k):\n",
    "    if k%1000==0:\n",
    "        print(k)\n",
    "        if k%1000==0:\n",
    "            print(time.asctime())\n",
    "    \n",
    "    if row.Acknowledgment_Tag is None or type(row.Acknowledgment_Tag) == float:\n",
    "        return []\n",
    "    \n",
    "    soup = BeautifulSoup(row.Acknowledgment_Tag,'lxml')\n",
    "\n",
    "    for ele in soup.find_all('title'):\n",
    "        ele.decompose()\n",
    "        \n",
    "    text = soup.find('ack')\n",
    "    if text is None:\n",
    "        return []\n",
    "    \n",
    "    text = text.get_text(separator=' ')\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    sentlist=[]\n",
    "    for sent in doc.sents:\n",
    "        #check for funding terminology and skip the sentence if found\n",
    "        fundwords = ['fund','grant','supported','financ','award']\n",
    "        if any([f in sent.text for f in fundwords]): continue\n",
    "        \n",
    "        #count nouns\n",
    "        badnamewords=['University','Research','Number','Doctoral','Postdoc','Scientist','Data','Surgeon','Centre','Center','Foundation','Universidad','Microscop','Microbio']\n",
    "        sentdoc = nlp(sent.text) #if this needs speed optimization, we can search by start-stop characters instead\n",
    "        sentppl = [n for n in sentdoc.ents if n.label_ == 'PERSON' and len(n.text.replace(\"\\n\",\" \").strip().split(' ')) > 1 and not any(c.isdigit() for c in n.text) and not any([f in n.text for f in badnamewords])]\n",
    "        people_count = len(sentppl)\n",
    "        if people_count == 0: continue #no named people, disregard\n",
    "            \n",
    "        \n",
    "            \n",
    "        #at least one person, populate a new item and add it to the list\n",
    "        item = {\"filename\":row.filename}\n",
    "        item[\"Text\"] = sent.text\n",
    "        item[\"Verbs\"] = ';'.join([ word.lemma_ for word in sentdoc if word.pos_ == 'VERB' and not word.is_stop])  \n",
    "        item[\"Nouns\"] = ';'.join([ word.text for word in sentdoc if word.pos_ == 'NOUN' and not word.is_stop])\n",
    "        item[\"Names\"] = ';'.join([ ent.text for ent in sentdoc.ents if ent.label_ == 'PERSON' and len(ent.text.split(' ')) > 1 ])\n",
    "        item[\"Organizations\"] = ';'.join([ ent.text for ent in sentdoc.ents if ent.label_ == 'ORG' ])\n",
    "        \n",
    "        genders=[]\n",
    "        genderprobs=[]\n",
    "        for name in sentppl:\n",
    "            \n",
    "            first_name = name.text.replace(\"\\n\",\" \").strip().split()[0]\n",
    "            #print(name.text.replace(\"\\n\",\" \").strip())\n",
    "            \n",
    "            if first_name not in known_names:\n",
    "                #print(first_name,'not recognized!')\n",
    "                continue\n",
    "\n",
    "            x = genderize.loc[first_name]\n",
    "            #print(first_name,x[\"gender\"],x['probability'])\n",
    "            genders.append( 1.0 * (x[\"gender\"] == 'female') )\n",
    "            genderprobs.append(x['probability'])\n",
    "        if genders: item['Is Female (Weighted)'] = np.average(genders,weights=genderprobs)\n",
    "\n",
    "        sentlist.append(item)\n",
    "        \n",
    "    return sentlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Tue Sep 11 20:36:33 2018\n",
      "1000\n",
      "Tue Sep 11 20:37:00 2018\n",
      "2000\n",
      "Tue Sep 11 20:37:32 2018\n",
      "3000\n",
      "Tue Sep 11 20:38:19 2018\n",
      "4000\n",
      "Tue Sep 11 20:39:12 2018\n",
      "5000\n",
      "Tue Sep 11 20:39:51 2018\n",
      "6000\n",
      "Tue Sep 11 20:40:40 2018\n",
      "7000\n",
      "Tue Sep 11 20:41:59 2018\n",
      "8000\n",
      "Tue Sep 11 20:42:17 2018\n"
     ]
    }
   ],
   "source": [
    "dx=[]\n",
    "for f in F_CSV:\n",
    "    df = pd.read_csv(f, nrows=15000)\n",
    "    \n",
    "    #dfunc = joblib.delayed(parse_df)\n",
    "    #with joblib.Parallel(1) as MP:\n",
    "    #    dx = MP(dfunc(row,k) for k,row in df.iterrows())\n",
    "    \n",
    "    for k,row in df.iterrows():\n",
    "        dx.extend(parse_df(row,k))\n",
    "     \n",
    "    dxtmp = pd.DataFrame(dx).set_index('filename')\n",
    "    f_save = os.path.join(\"../parsed_data/sentence_parse/\",\n",
    "                          'gendered_sentences.csv.part')\n",
    "    dxtmp.to_csv(f_save)\n",
    "    \n",
    "dx = pd.DataFrame(dx).set_index('filename')\n",
    "f_save = os.path.join(\"../parsed_data/sentence_parse/\",\n",
    "                          'gendered_sentences.csv')\n",
    "dx.to_csv(f_save)\n",
    "dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
