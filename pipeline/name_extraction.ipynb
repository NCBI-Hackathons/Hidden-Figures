{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import spacy as sp\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from spacy import displacy\n",
    "import joblib\n",
    "from multiprocessing import Pool\n",
    "\n",
    "#The 'xx' dataset is the biggest multilanguage one.  It catches the most names\n",
    "#The 'en' dataset does the best job of parsing organizations and labels verbs and other parts of speech\n",
    "# Install model with `python -m spacy download en`\n",
    "\n",
    "nlp = sp.load('en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acknowledgments The project was supported by a start-up funding provided to the author by the  Department of Neurology of the University of Utah . This project was inspired by studying the work of Dr. Ed Dudek and the results of the initial experiments were discussed with him. I am also grateful to Dr. Erika Scholl for her assistance in measuring rat serum osmolarity and to Dr. Noel Carlson for his insightful comments on the manuscript.\n",
      "the  Department of Neurology of the University of Utah 90 144 ORG\n",
      "Ed Dudek 201 209 PERSON\n",
      "Erika Scholl 304 316 PERSON\n",
      "Noel Carlson 381 393 PERSON\n"
     ]
    }
   ],
   "source": [
    "# Sample read\n",
    "sample = '<ack><title>Acknowledgements</title><p>The authors wish to acknowledge Diya Ma, Matthew-Lun Wong, Ka-Long Ko, Ka-Hei Ko and Jin-Peng Lee for their important contributions to the software development.</p><sec id=\"\"FPar1\"\"><title>Funding</title><p id=\"\"Par28\"\">The work described in this paper was supported by a grant from the Research Grants Council of the Hong Kong Special Administrative Region, China (Project No.: CUHK 14113214), grants from the Innovation and Technology Commission (Project No: ITS/149/14FP, GHP/028/14SZ, ITS/293/14FP), grants from CUHK Technology and Business Development Fund (Project No.: TBF16MED002, TBF16MED004), a grant from The Science, Technology and Innovation Commission of Shenzhen Municipality (Project No.: CXZZ20140606164105361), and a grant from The Scientific Research Project of Guangdong Province (Project No.: 2014B090901055).</p></sec></ack>'\n",
    "sample2 = '<ack id=\"\"ack0010\"\"><title>Acknowledgements</title><p>The authors thank Dr. R Kaneko for the gift of the iSip2 vector; and Mss. T Honma, K Harada, A Morita, and Y Shimoda for providing technical and secretarial assistance. We thank the staff at the Department of Genetic and Behavioral Neuroscience and Bioresource Center, Gunma University Graduate School of Medicine for their critical comments and technical assistance. This study was supported by <funding-source id=\"\"gs1\"\">Grants-in-Aid for Scientific Research</funding-source> (23115503, 26290002, 15H01415 and 15H05872 to Y.Y.), a Grant-in-Aid for Scientific Research on Innovative Areas (Comprehensive Brain Science Network) (to Y.Y.) from the <funding-source id=\"\"gs2\"\">Ministry of Education, Culture, Sports, Science and Technology (MEXT)</funding-source> of Japan, a grant from the Co-operative Study Program of the <funding-source id=\"\"gs3\"\">National Institute for Physiological Sciences</funding-source>, Japan (to Y.Y.), and a grant from the <funding-source id=\"\"gs4\"\">Takeda Science Foundation</funding-source> (to Y.Y.).</p></ack>'\n",
    "sample = u'<ack id=\"\"ack0005\"\"><title>Acknowledgments</title><p>The project was supported by a start-up funding provided to the author by the <funding-source id=\"\"gs0005\"\">Department of Neurology of the University of Utah</funding-source>.</p><p>This project was inspired by studying the work of Dr. Ed Dudek and the results of the initial experiments were discussed with him.</p><p>I am also grateful to Dr. Erika Scholl for her assistance in measuring rat serum osmolarity and to Dr. Noel Carlson for his insightful comments on the manuscript.</p></ack>'\n",
    "\n",
    "soup = BeautifulSoup(sample,'lxml')\n",
    "samp_txt = soup.find_all('ack')[0].get_text(separator=' ')\n",
    "\n",
    "print(samp_txt)\n",
    "doc = nlp(samp_txt)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_CSV = glob.glob(\"../source_data/extracted/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_df(row, k):\n",
    "    if k%1000==0:\n",
    "        print(k)\n",
    "    \n",
    "    item = {\"filename\":row.filename}\n",
    "    if row.Acknowledgment_Tag is None or type(row.Acknowledgment_Tag) == float:\n",
    "        return item\n",
    "    \n",
    "    soup = BeautifulSoup(row.Acknowledgment_Tag,'lxml')\n",
    "\n",
    "    for ele in soup.find_all('title'):\n",
    "        ele.decompose()\n",
    "        \n",
    "    text = soup.find('ack')\n",
    "    \n",
    "    if text is None:\n",
    "        return item\n",
    "    \n",
    "    text = text.get_text(separator=' ')\n",
    "    \n",
    "    doc = nlp(text)\n",
    "\n",
    "    item[\"Verbs\"] = ';'.join([ word.lemma_ for word in doc if word.pos_ == 'VERB' and not word.is_stop])  \n",
    "    item[\"Nouns\"] = ';'.join([ word.text for word in doc if word.pos_ == 'NOUN' and not word.is_stop])\n",
    "    item[\"Names\"] = ';'.join([ ent.text for ent in doc.ents if ent.label_ == 'PERSON' and len(ent.text.split(' ')) > 1 ])\n",
    "    item[\"Organizations\"] = ';'.join([ ent.text for ent in doc.ents if ent.label_ == 'ORG' ])\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in F_CSV:\n",
    "    df = pd.read_csv(f, nrows=2000)\n",
    "    \n",
    "    dfunc = joblib.delayed(parse_df)\n",
    "    with joblib.Parallel(1) as MP:\n",
    "        dx = MP(dfunc(row,k) for k,row in df.iterrows())\n",
    "        \n",
    "    dx = pd.DataFrame(dx)\n",
    "    f_save = os.path.join(\"../parsed_data/new_parse/\",\n",
    "                          os.path.basename(f))\n",
    "    dx.to_csv(f_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
