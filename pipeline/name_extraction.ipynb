{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d3a43efa09a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import spacy as sp\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from spacy import displacy\n",
    "from multiprocessing import Pool\n",
    "    \n",
    "#The 'xx' dataset is the biggest multilanguage one.  It catches the most names\n",
    "#The 'en' dataset does the best job of parsing organizations and labels verbs and other parts of speech\n",
    "nlp = sp.load('en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#commented out to keep code we may want to use later\n",
    "if False: '''\n",
    "sample = '<ack><title>Acknowledgements</title><p>The authors wish to acknowledge Diya Ma, Matthew-Lun Wong, Ka-Long Ko, Ka-Hei Ko and Jin-Peng Lee for their important contributions to the software development.</p><sec id=\"\"FPar1\"\"><title>Funding</title><p id=\"\"Par28\"\">The work described in this paper was supported by a grant from the Research Grants Council of the Hong Kong Special Administrative Region, China (Project No.: CUHK 14113214), grants from the Innovation and Technology Commission (Project No: ITS/149/14FP, GHP/028/14SZ, ITS/293/14FP), grants from CUHK Technology and Business Development Fund (Project No.: TBF16MED002, TBF16MED004), a grant from The Science, Technology and Innovation Commission of Shenzhen Municipality (Project No.: CXZZ20140606164105361), and a grant from The Scientific Research Project of Guangdong Province (Project No.: 2014B090901055).</p></sec></ack>'\n",
    "sample2 = '<ack id=\"\"ack0010\"\"><title>Acknowledgements</title><p>The authors thank Dr. R Kaneko for the gift of the iSip2 vector; and Mss. T Honma, K Harada, A Morita, and Y Shimoda for providing technical and secretarial assistance. We thank the staff at the Department of Genetic and Behavioral Neuroscience and Bioresource Center, Gunma University Graduate School of Medicine for their critical comments and technical assistance. This study was supported by <funding-source id=\"\"gs1\"\">Grants-in-Aid for Scientific Research</funding-source> (23115503, 26290002, 15H01415 and 15H05872 to Y.Y.), a Grant-in-Aid for Scientific Research on Innovative Areas (Comprehensive Brain Science Network) (to Y.Y.) from the <funding-source id=\"\"gs2\"\">Ministry of Education, Culture, Sports, Science and Technology (MEXT)</funding-source> of Japan, a grant from the Co-operative Study Program of the <funding-source id=\"\"gs3\"\">National Institute for Physiological Sciences</funding-source>, Japan (to Y.Y.), and a grant from the <funding-source id=\"\"gs4\"\">Takeda Science Foundation</funding-source> (to Y.Y.).</p></ack>'\n",
    "sample = u'<ack id=\"\"ack0005\"\"><title>Acknowledgments</title><p>The project was supported by a start-up funding provided to the author by the <funding-source id=\"\"gs0005\"\">Department of Neurology of the University of Utah</funding-source>.</p><p>This project was inspired by studying the work of Dr. Ed Dudek and the results of the initial experiments were discussed with him.</p><p>I am also grateful to Dr. Erika Scholl for her assistance in measuring rat serum osmolarity and to Dr. Noel Carlson for his insightful comments on the manuscript.</p></ack>'\n",
    "\n",
    "soup = BeautifulSoup(sample,'lxml')\n",
    "\n",
    "samp_txt = soup.find_all('ack')[0].get_text(separator=' ')\n",
    "\n",
    "print(samp_txt)\n",
    "\n",
    "doc = nlp(samp_txt)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print('works')\n",
    "#for token in doc:\n",
    "#    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "#          token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File A-B 0\n",
      "File C-H 0\n",
      "File I-N 0\n",
      "File O-Z 0\n"
     ]
    }
   ],
   "source": [
    "files = ['A-B','C-H','I-N','O-Z']\n",
    "\n",
    "for f in files:    \n",
    "    df = pd.read_csv(''.join(['~/HackathonData/extracted/articles.',f,'.xml.tar.gz.csv']))\n",
    "\n",
    "    newdf = pd.DataFrame(df['filename'][:10])\n",
    "    #print([r for r in newdf.iterrows()])\n",
    "    newdf.insert(1, 'Names', ['' for r in newdf.iterrows()])\n",
    "    newdf.insert(2, 'Organizations', ['' for r in newdf.iterrows()])\n",
    "    newdf.insert(3, 'Verbs', ['' for r in newdf.iterrows()])\n",
    "    newdf.insert(4, 'Nouns', ['' for r in newdf.iterrows()])\n",
    "    \n",
    "    namestrs=[]\n",
    "    for erow,row in enumerate(df['Acknowledgment_Tag'][:10]):\n",
    "        if erow%1000 == 0: print(\"File\",f,erow)\n",
    "        if not isinstance(row,str): row = '<ack></ack>'\n",
    "        soup = BeautifulSoup(row,'lxml')\n",
    "\n",
    "        for ele in soup.find_all('title'):\n",
    "            ele.decompose()\n",
    "        samp_txt = soup.find_all('ack')[0].get_text(separator=' ')\n",
    "\n",
    "        doc = nlp(samp_txt)\n",
    "        \n",
    "        verbstr = ';'.join([ word.lemma_ for word in doc if word.pos_ == 'VERB' and not word.is_stop])\n",
    "        newdf.at[erow, 'Verbs'] = verbstr\n",
    "        \n",
    "        nnstr = ';'.join([ word.text for word in doc if word.pos_ == 'NOUN' and not word.is_stop])\n",
    "        newdf.at[erow, 'Nouns'] = nnstr\n",
    "\n",
    "        namestr = ';'.join([ ent.text for ent in doc.ents if ent.label_ == 'PERSON' and len(ent.text.split(' ')) > 1 ])\n",
    "        newdf.at[erow, 'Names'] = namestr\n",
    "        \n",
    "        orgstr = ';'.join([ ent.text for ent in doc.ents if ent.label_ == 'ORG' ])\n",
    "        newdf.at[erow, 'Organizations'] = orgstr\n",
    "        \n",
    "\n",
    "\n",
    "    #print(newdf)\n",
    "    newdf.to_csv(''.join(['Extracted Names ',f,'.csv']))\n",
    "    #print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
